{
  "courses": [
    {
      "id": "foundations",
      "title": "Foundations",
      "description": "Journey through probability \u2014 from coin flips to random variables",
      "slug": "foundations",
      "lessons": 3,
      "status": "published",
      "createdAt": "2025-10-25T11:37:21.531Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "chains",
      "title": "Markov Chain Basics",
      "description": "Discover how probability evolves: state transitions, convergence, and equilibrium",
      "slug": "markov-chain-basics",
      "lessons": 7,
      "status": "published",
      "createdAt": "2025-10-25T11:37:21.531Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "ctmc",
      "title": "Continuous-Time Markov Processes",
      "description": "When time flows continuously: exponential clocks and queueing systems",
      "slug": "continuous-time-markov-processes",
      "status": "published",
      "createdAt": "2025-10-25T14:00:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z",
      "lessons": 5
    },
    {
      "id": "stochastic-advanced",
      "title": "Advanced Stochastic Adventures",
      "description": "Martingales, MDPs, and the cutting edge of probability theory",
      "slug": "stochastic-advanced",
      "status": "published",
      "createdAt": "2025-10-25T14:05:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z",
      "lessons": 5
    },
    {
      "id": "markov-simulations",
      "title": "Simulation and Applications",
      "description": "From theory to code: Monte Carlo, MCMC, and PageRank",
      "slug": "markov-simulations",
      "status": "published",
      "createdAt": "2025-10-25T14:10:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z",
      "lessons": 5
    }
  ],
  "lessons": [
    {
      "id": "foundations-1",
      "courseId": "foundations",
      "title": "The Language of Uncertainty",
      "description": "Master the axiomatic foundation of probability: sample spaces, events, and Kolmogorov's three elegant axioms.",
      "content": "# The Language of Uncertainty\n\nImagine you're Neo from *The Matrix*, standing at a crossroads. You don't know which path leads where, but you need to make a decision. This is the essence of **epistemic uncertainty** \u2014 and probability theory is your map through this stochastic landscape.\n\nWelcome to your first lesson in probability theory! Here, we'll construct the **mathematical infrastructure** for reasoning about randomness, which will later empower us to explore how dynamical systems evolve through Markov chains.\n\n## The Philosophical Foundation\n\nEvery decision we make operates under **incomplete information**. Consider these scenarios:\n\n- Will it rain tomorrow? (Meteorological forecasting)\n- Will your team win the championship? (Sports analytics)\n- What's the probability a new startup disrupts an industry? (Risk assessment)\n\n**Probability theory** provides us with a *rigorous axiomatic framework* to quantify these uncertainties and construct rational decision-making systems.\n\n## The Fundamental Constructs\n\n### Sample Space: The Universe of Possibilities\n\nThe **sample space** (denoted $\\Omega$, capital omega) represents the set of all *mutually exclusive* and *collectively exhaustive* outcomes of a random experiment.\n\n**Formal Definition:**\n```math\n\\Omega = \\{\\omega_1, \\omega_2, \\ldots, \\omega_n\\}\n```\n\nwhere each $\\omega_i$ represents an atomic outcome.\n\n**Example:** Rolling a standard six-sided die yields:\n```math\n\\Omega = \\{1, 2, 3, 4, 5, 6\\}\n```\n\nEach outcome is **equiprobable** under the assumption of fairness, embodying the **principle of indifference** (also called the **principle of insufficient reason**, attributed to Laplace).\n\n### Events: Measurable Subsets\n\nAn **event** $A$ is a subset of the sample space \u2014 formally, an element of the **sigma-algebra** $\\mathcal{F}$ defined on $\\Omega$.\n\n**Definition:**\n```math\nA \\subseteq \\Omega, \\quad A \\in \\mathcal{F}\n```\n\n**Example:** Define event $A$ = \"rolling an even number\"\n\nThen:\n```math\nA = \\{2, 4, 6\\} \\subset \\Omega\n```\n\nEvents can be:\n- **Elementary** (singleton sets): $\\{3\\}$\n- **Compound** (multiple outcomes): $\\{2, 4, 6\\}$\n- **Certain** (the entire sample space): $\\Omega$\n- **Impossible** (the empty set): $\\emptyset$\n\n### Kolmogorov's Axioms: The Rules of the Game\n\nIn 1933, Andrey Kolmogorov established the **axiomatic foundation** of modern probability theory. Think of these as the \"rules of reality\" \u2014 like the laws of physics in *Star Trek*, even in alternate universes, these axioms hold.\n\nGiven a sample space $\\Omega$ and a sigma-algebra $\\mathcal{F}$, a probability measure $P: \\mathcal{F} \\to [0,1]$ satisfies:\n\n**Axiom 1 (Non-negativity):**\n```math\nP(A) \\geq 0, \\quad \\forall A \\in \\mathcal{F}\n```\n\nProbabilities are never negative. This ensures **physical realizability**.\n\n**Axiom 2 (Normalization):**\n```math\nP(\\Omega) = 1\n```\n\nSomething must happen. The total probability mass equals unity. Like in *The Hitchhiker's Guide*, the answer may be 42, but certainty is always 1.\n\n**Axiom 3 (Countable Additivity):**\n\nFor any countable collection of **mutually disjoint** events $\\{A_1, A_2, \\ldots\\}$:\n\n```math\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i)\n```\n\nThis is the **additivity principle** \u2014 probabilities of disjoint events sum.\n\n> **Historical Note:** These axioms resolved centuries of philosophical debate about probability. Before Kolmogorov, probability was a mess of intuitions and paradoxes \u2014 like trying to define \"time\" before Einstein gave us special relativity.\n\n## The Classical Probability Model\n\nUnder the assumption of **equally likely outcomes** (the **classical model**), we have:\n\n```math\nP(A) = \\frac{|A|}{|\\Omega|} = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\n```\n\nwhere $|A|$ denotes the **cardinality** of set $A$.\n\n### Worked Example: The Fair Coin\n\nConsider flipping a fair coin. The sample space is:\n\n```math\n\\Omega = \\{H, T\\}\n```\n\nAssuming fairness (symmetry):\n```math\nP(H) = P(T) = \\frac{1}{2}\n```\n\nVerify Axiom 2:\n```math\nP(\\Omega) = P(H) + P(T) = \\frac{1}{2} + \\frac{1}{2} = 1 \\quad \\checkmark\n```\n\nThe axioms are consistent! This simple experiment is the **prototype** for countless probability models, from quantum mechanics (spin measurements) to computer science (random bit generation).\n\n### Worked Example: The Lucky Die\n\n**Problem:** What is $P(A)$ where $A$ = \"rolling less than 4\"?\n\n**Solution:**\n\nDefine the event explicitly:\n```math\nA = \\{1, 2, 3\\}\n```\n\nSince all outcomes are equiprobable under the classical model:\n```math\nP(A) = \\frac{|A|}{|\\Omega|} = \\frac{3}{6} = \\frac{1}{2} = 0.5\n```\n\n**Answer:** There is a 50% probability of rolling less than 4.\n\n> **\ud83d\udca1 Interactive Visualization Coming Soon!**\n> \n> *Explore probability with dynamic Venn diagrams \u2014 drag events, adjust probabilities, and watch the axioms come to life in real-time. Like the holodeck from Star Trek, but for mathematics!*\n\n## Applications Across Disciplines\n\nProbability theory is not merely abstract mathematics \u2014 it's the **lingua franca** of uncertainty quantification.\n\n**Meteorology:** Weather forecasting relies on probabilistic models to predict atmospheric dynamics. The \"30% chance of rain\" is a **conditional probability** statement given current observations.\n\n**Quality Control:** Manufacturing processes use **statistical process control** (SPC) to estimate defect rates via probability distributions, minimizing Type I and Type II errors.\n\n**Finance:** Modern portfolio theory (Markowitz, 1952) uses probability to model expected returns and risk (variance), enabling optimal asset allocation.\n\n**Machine Learning:** Every classification algorithm \u2014 from logistic regression to deep neural networks \u2014 fundamentally computes conditional probabilities $P(y|x)$ where $y$ is the label and $x$ is the input feature vector.\n\n**Quantum Mechanics:** The **Born rule** interprets the wavefunction $|\\psi\\rangle$ as encoding probability amplitudes, with $|\\langle x|\\psi\\rangle|^2$ giving the probability density of measuring position $x$.\n\n## Practice Problems\n\n> **Problem 1:** Roll a fair six-sided die. Compute $P(B)$ where $B$ = \"rolling greater than 4\".\n> \n> **Problem 2:** A bag contains 3 red, 2 blue, and 5 green marbles. Using the classical model, calculate $P(\\text{green})$.\n> \n> **Problem 3 (Challenging):** Can two mutually exclusive events $A$ and $B$ (where $A \\cap B = \\emptyset$) also be statistically independent? Prove or provide a counterexample. *Hint: Recall that independence requires $P(A \\cap B) = P(A) \\cdot P(B)$.*\n\n## The Conceptual Map\n\nYou've now acquired the fundamental **vocabulary** of probability:\n\n1. **Sample spaces** ($\\Omega$) define the universe of possibilities\n2. **Events** ($A \\subseteq \\Omega$) represent measurable outcomes\n3. **Probability measures** ($P$) satisfy Kolmogorov's three axioms\n4. **Classical model** assumes equiprobable outcomes\n\nThese concepts form the **algebraic structure** upon which all of stochastic analysis rests. Like learning the alphabet before reading Shakespeare, you now have the symbols to construct probabilistic narratives.\n\n## The Road Ahead\n\nIn our next lesson, we'll explore **conditional probability** and **Bayes' theorem** \u2014 the mathematical machinery that updates beliefs when new evidence arrives. Think of it as the \"plot twist\" mechanism in probability theory.\n\nAs Sherlock Holmes might say: *\"When you have eliminated the impossible, whatever remains, however improbable, must be the truth.\"* Bayes' theorem gives us the mathematical framework to actually compute those probabilities!\n",
      "status": "published",
      "order": 1,
      "createdAt": "2025-10-25T12:59:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "foundations-2",
      "courseId": "foundations",
      "title": "When Information Changes Everything",
      "description": "Discover how new evidence transforms probabilities through conditional probability and Bayes' theorem.",
      "content": "# When Information Changes Everything\n\nPicture this: You're watching the sky. Dark clouds gather. Suddenly, the probability of rain isn't just a number \u2014 it's *updated* by what you see.\n\nThis is the power of **conditional probability**: understanding how new information reshapes our beliefs.\n\n## The Mystery of the Medical Test\n\nImagine a disease that affects 1% of people. A test detects it 95% of the time when present, but gives false positives 2% of the time for healthy people.\n\n**You test positive.** Should you panic?\n\nLet's find out using the tools you'll learn in this lesson.\n\n## Conditional Probability: Zooming In\n\nThe **conditional probability** P(A|B) asks: \"What's the probability of A, *given* that B has occurred?\"\n\n```math\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{when } P(B) > 0\n```\n\n**Intuition:** If we know B happened, our sample space shrinks to B. We then measure how much of B overlaps with A.\n\n> **\ud83d\udca1 Interactive Visualization Coming Soon!**\n> \n> *Watch Venn diagrams dynamically shrink and highlight as you apply conditions \u2014 see conditional probability in action!*\n\n## Story 1: Drawing Cards\n\nA standard deck has 52 cards. What's P(Ace | Spade)?\n\n**Solution:**\n- A = {card is Ace}, B = {card is Spade}\n- A \u2229 B = {Ace of Spades}\n- P(A \u2229 B) = 1/52, P(B) = 13/52\n\n```math\nP(A|B) = \\frac{1/52}{13/52} = \\frac{1}{13}\n```\n\n**Answer:** Among spades, 1 in 13 is an Ace.\n\n## Bayes' Theorem: The Information Reverser\n\nBayes' theorem is a superpower \u2014 it lets you *reverse* conditional probabilities:\n\n```math\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n```\n\nThis connects:\n- **Prior belief** P(A)\n- **Likelihood** P(B|A) \n- **Posterior belief** P(A|B)\n\n## Back to the Medical Test\n\nLet D = \"has disease\", T = \"tests positive\"\n\nGiven:\n- P(D) = 0.01 (prior)\n- P(T|D) = 0.95 (true positive rate)\n- P(T|\u00acD) = 0.02 (false positive rate)\n\n**Find:** P(D|T) \u2014 probability you have the disease given a positive test.\n\n**Step 1:** Compute P(T) using total probability:\n\n```math\nP(T) = P(T|D)P(D) + P(T|\u00acD)P(\u00acD)\n     = (0.95)(0.01) + (0.02)(0.99)\n     = 0.0293\n```\n\n**Step 2:** Apply Bayes' theorem:\n\n```math\nP(D|T) = \\frac{P(T|D) \\cdot P(D)}{P(T)} = \\frac{0.95 \\times 0.01}{0.0293} \\approx 0.324\n```\n\n**Surprising Answer:** Even with a positive test, there's only a 32% chance you have the disease!\n\nThis is because the disease is rare (low prior), so most positives are false alarms.\n\n> **\ud83d\udca1 Interactive Bayes Calculator Coming Soon!**\n> \n> *Adjust priors, likelihoods, and see posteriors update instantly \u2014 perfect for understanding medical tests, spam filters, and more!*\n\n## Where This Matters\n\n\n\n\n\n## Your Turn\n\n**Practice Questions:**\n1. A biased coin has P(H) = 0.6. If flipped twice, what's P(first = H | total heads = 1)?\n2. A machine makes 5% defects. A test catches 90% of defects and flags 3% of good items. Find P(defect | flagged).\n3. Explain in your own words how Bayes' theorem \"reverses\" conditional probabilities.\n\n## The Journey Continues\n\nYou've now mastered:\n- **Conditional probability** \u2014 updating beliefs with evidence\n- **Bayes' theorem** \u2014 the mathematical engine of inference\n- **Real-world impact** \u2014 from medicine to AI\n\n**Next Adventure:** Random variables and expectations \u2014 turning probability into numbers we can compute and predict!\n",
      "status": "published",
      "order": 2,
      "createdAt": "2025-10-25T13:06:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "foundations-3",
      "courseId": "foundations",
      "title": "Random Variables and Expectations",
      "description": "An introduction to random variables, probability distributions, and the concept of expected value as the center of probability.",
      "content": "# Random Variables and Expectations\n\nIn previous lessons, we discussed how probabilities describe uncertainty in terms of events. Now we extend these ideas to **random variables**, which assign numerical values to outcomes — enabling us to measure, compute, and model uncertainty quantitatively.\n\n## What Is a Random Variable?\n\nA **random variable (RV)** is a function that maps outcomes of a random experiment to real numbers.\n\n```math\nX: Ω → ℝ\n```\n\nFor each outcome ω ∈ Ω, X(ω) gives a number.\n\n### Types of Random Variables\n1. **Discrete random variables** — take on a countable number of values (e.g., number of heads in 3 tosses).\n2. **Continuous random variables** — take on values from an interval (e.g., height, time, temperature).\n\n## Probability Distributions\n\n### 1. Probability Mass Function (PMF)\nFor discrete X:\n\n```math\nP(X = xᵢ) = p(xᵢ), \\quad \\text{where } ∑ p(xᵢ) = 1\n```\n\n### 2. Probability Density Function (PDF)\nFor continuous X:\n\n```math\nP(a ≤ X ≤ b) = ∫ₐᵇ f(x) dx, \\quad \\text{where } ∫_{-∞}^{∞} f(x) dx = 1\n```\n\n### 3. Cumulative Distribution Function (CDF)\nFor any X:\n\n```math\nF(x) = P(X ≤ x)\n```\n\nThe CDF increases from 0 to 1 as x moves across the support of X.\n\n## Worked Examples\n\n### Example 1: Rolling a Die\nLet X = number shown when rolling a fair six-sided die.\n\nThen X takes values {1, 2, 3, 4, 5, 6} with equal probabilities:\n\n```math\np(x) = 1/6, \\quad x = 1,2,...,6\n```\n\n### Example 2: Number of Heads in 2 Tosses\nLet X = number of heads. Possible outcomes are HH, HT, TH, TT.\n\n| X | Outcome | P(X=x) |\n|---|----------|--------|\n| 0 | TT | 1/4 |\n| 1 | HT, TH | 1/2 |\n| 2 | HH | 1/4 |\n\nThe PMF satisfies ∑ P(X=x) = 1.\n\n## Expected Value\n\nThe **expected value (mean)** of X represents the long-term average if the experiment were repeated many times.\n\n- For discrete X:\n\n```math\nE[X] = ∑ x·P(X=x)\n```\n\n- For continuous X:\n\n```math\nE[X] = ∫ x f(x) dx\n```\n\n### Example 3: Expectation for a Die Roll\n\n```math\nE[X] = (1)(1/6) + (2)(1/6) + ... + (6)(1/6) = 3.5\n```\n\nOn average, you expect 3.5 from a fair die roll.\n\n## Interactive Visualization: Die Roll Probabilities\n\nLet's visualize the probability distribution for a fair six-sided die:\n\n```chart\n{\n  \"type\": \"bar\",\n  \"data\": [\n    {\"name\": \"1\", \"value\": 0.167},\n    {\"name\": \"2\", \"value\": 0.167},\n    {\"name\": \"3\", \"value\": 0.167},\n    {\"name\": \"4\", \"value\": 0.167},\n    {\"name\": \"5\", \"value\": 0.167},\n    {\"name\": \"6\", \"value\": 0.167}\n  ]\n}\n```\n\nNotice how each outcome has equal probability (1/6 ≈ 0.167). This is what we call a **uniform distribution**.\n\n## Variance and Standard Deviation\n\nThe **variance** measures spread:\n\n```math\nVar(X) = E[(X - E[X])²] = E[X²] - (E[X])²\n```\n\nThe **standard deviation** is the square root of the variance.\n\n### Example 4: Variance of a Die Roll\n\n```math\nE[X²] = (1² + 2² + 3² + 4² + 5² + 6²)/6 = 91/6\nVar(X) = 91/6 - 3.5² = 35/12 ≈ 2.92\n```\n\nSo the standard deviation is √2.92 ≈ 1.71.\n\n## Visualization\n\nImagine plotting the PMF as a bar chart — each bar’s height shows P(X=x). For a continuous variable, imagine a smooth curve (PDF) whose area under the curve equals 1.\n\nInteractive plots can help students visualize how **expected value** shifts when the distribution is skewed.\n\n## Real-World Applications\n- **Finance:** Expected return on investment.\n- **Insurance:** Expected payout and premium setting.\n- **Manufacturing:** Expected defect count.\n- **AI/ML:** Expected loss functions in optimization.\n\n## Practice Prompts\n1. A fair coin is tossed 3 times. Let X = number of heads. Find E[X] and Var(X).\n2. Suppose X can take values {0, 1, 2} with P(X=0)=0.2, P(X=1)=0.5, P(X=2)=0.3. Compute E[X] and Var(X).\n3. Explain in words why the expected value may not always be a possible outcome (e.g., E[X]=3.5 for a die).\n\n## Key Takeaways\n- Random variables connect events to numerical outcomes.\n- Discrete → PMF, Continuous → PDF.\n- Expectation represents the long-run average.\n- Variance quantifies how spread out the outcomes are.\n\n**Next:** In the next course, we’ll apply these concepts to dynamic systems — *Markov Chains*, where probabilities evolve across states over time.\n",
      "status": "published",
      "order": 3,
      "createdAt": "2025-10-25T13:12:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "chains-1",
      "courseId": "chains",
      "title": "Enter the Markov Chain: Memory-Free Transitions",
      "description": "Discover the memoryless property and see your first Markov chain in action.",
      "content": "# Enter the Markov Chain: Memory-Free Transitions\n\nImagine a system that evolves through time, jumping from state to state. **But here's the twist:** the future depends *only* on where you are now, not on how you got there.\n\nThis is the **Markov property** \u2014 and it unlocks an entire universe of stochastic models.\n\n## The Big Idea\n\nA **Markov chain** is a sequence of random states where:\n\n> The probability of the next state depends only on the current state, not on past history.\n\nMathematically:\n\n```math\nP(X_{n+1} = j \\mid X_n = i, X_{n-1}, X_{n-2}, \\ldots) = P(X_{n+1} = j \\mid X_n = i)\n```\n\n**Translation:** \"Where you go next depends only on where you are now \u2014 your past is irrelevant.\"\n\n## Story 1: The Weather Model\n\nConsider a simple weather system with two states:\n- **S** = Sunny\n- **R** = Rainy\n\nObservations show:\n- After a sunny day, 70% of tomorrows are sunny, 30% rainy\n- After a rainy day, 40% of tomorrows are sunny, 60% rainy\n\n**Transition Matrix:**\n\n```matrix\n        S     R\n  S [ 0.7   0.3 ]\n  R [ 0.4   0.6 ]\n```\n\nEach row shows where you can go from that state. Rows sum to 1 (you must go somewhere).\n\n> **\ud83d\udca1 Interactive State Diagram Coming Soon!**\n> \n> *Visualize states as nodes and transitions as arrows \u2014 click to follow the chain through time!*\n\n## The Anatomy of a Markov Chain\n\n### 1. State Space\nThe set of all possible states: S = {S, R} in our weather example.\n\n### 2. Transition Probabilities\nP(i\u2192j) = probability of moving from state i to state j.\n\n### 3. Initial Distribution\nWhere does the chain start? \u03c0\u2080 = [P(start in S), P(start in R)].\n\n## Simulating the Weather\n\nStart on a sunny day. Use the transition matrix to generate next days:\n\n- Day 0: S (given)\n- Day 1: With prob 0.7 \u2192 S, with prob 0.3 \u2192 R. Say we get S.\n- Day 2: From S, again 0.7 \u2192 S, 0.3 \u2192 R. Say we get R.\n- Day 3: From R, 0.4 \u2192 S, 0.6 \u2192 R. Say we get R.\n- ...\n\nThe sequence {S, S, R, R, ...} is one **realization** of the Markov chain.\n\n## Why \"Memoryless\" Matters\n\nThe memoryless property makes Markov chains:\n- **Tractable** \u2014 easy to analyze mathematically\n- **Efficient** \u2014 need only track current state\n- **Widely applicable** \u2014 many real systems have this property (or approximate it)\n\n## Where You'll Find Markov Chains\n\n\n\n\n\n## Explore Convergence\n\nHere's a related question: if you flip a coin many times, does the proportion of heads converge to the true probability?\n\n**Spoiler:** Yes! This is the **Law of Large Numbers** in action.\n\n```component\n{\"name\":\"FlipConvergence\",\"props\":{\"p\":0.7,\"trials\":600,\"updateIntervalMs\":25,\"batch\":40,\"height\":400}}\n```\n\n**Try it:** Adjust the true probability (p) and watch convergence. This same idea applies to Markov chains \u2014 long-run frequencies converge to steady-state probabilities!\n\n## Your Turn\n\n**Practice Questions:**\n1. Draw a state diagram for a 3-state chain: {A, B, C} with transitions A\u2192B (0.5), A\u2192C (0.5), B\u2192A (1.0), C\u2192A (1.0).\n2. Explain why the Markov property is \"memoryless.\"\n3. Can you think of a real-world process that is NOT Markovian? (Hint: stock prices with trends)\n\n## The Adventure Begins\n\nYou've just entered the world of Markov chains:\n- **States** represent positions in the system\n- **Transitions** govern movement between states\n- **Memoryless** \u2014 only the present matters\n\n**Next:** We'll dig deeper into transition matrices and learn how to compute multi-step probabilities!\n",
      "status": "published",
      "order": 1,
      "createdAt": "2025-10-25T11:37:21.531Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    }
  ]
}