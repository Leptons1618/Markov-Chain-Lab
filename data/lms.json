{
  "courses": [
    {
      "id": "foundations",
      "title": "Foundations",
      "description": "Journey through probability \u2014 from coin flips to random variables",
      "slug": "foundations",
      "lessons": 3,
      "status": "published",
      "createdAt": "2025-10-25T11:37:21.531Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "chains",
      "title": "Markov Chain Basics",
      "description": "Discover how probability evolves: state transitions, convergence, and equilibrium",
      "slug": "markov-chain-basics",
      "lessons": 7,
      "status": "published",
      "createdAt": "2025-10-25T11:37:21.531Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "ctmc",
      "title": "Continuous-Time Markov Processes",
      "description": "When time flows continuously: exponential clocks and queueing systems",
      "slug": "continuous-time-markov-processes",
      "status": "published",
      "createdAt": "2025-10-25T14:00:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z",
      "lessons": 5
    },
    {
      "id": "stochastic-advanced",
      "title": "Advanced Stochastic Adventures",
      "description": "Martingales, MDPs, and the cutting edge of probability theory",
      "slug": "stochastic-advanced",
      "status": "published",
      "createdAt": "2025-10-25T14:05:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z",
      "lessons": 5
    },
    {
      "id": "markov-simulations",
      "title": "Simulation and Applications",
      "description": "From theory to code: Monte Carlo, MCMC, and PageRank",
      "slug": "markov-simulations",
      "status": "published",
      "createdAt": "2025-10-25T14:10:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z",
      "lessons": 5
    }
  ],
  "lessons": [
    {
      "id": "foundations-1",
      "courseId": "foundations",
      "title": "The Language of Uncertainty",
      "description": "Master the axiomatic foundation of probability: sample spaces, events, and Kolmogorov's three elegant axioms.",
      "content": "# The Language of Uncertainty\n\nImagine you're Neo from *The Matrix*, standing at a crossroads. You don't know which path leads where, but you need to make a decision. This is the essence of **epistemic uncertainty** \u2014 and probability theory is your map through this stochastic landscape.\n\nWelcome to your first lesson in probability theory! Here, we'll construct the **mathematical infrastructure** for reasoning about randomness, which will later empower us to explore how dynamical systems evolve through Markov chains.\n\n## The Philosophical Foundation\n\nEvery decision we make operates under **incomplete information**. Consider these scenarios:\n\n- Will it rain tomorrow? (Meteorological forecasting)\n- Will your team win the championship? (Sports analytics)\n- What's the probability a new startup disrupts an industry? (Risk assessment)\n\n**Probability theory** provides us with a *rigorous axiomatic framework* to quantify these uncertainties and construct rational decision-making systems.\n\n## The Fundamental Constructs\n\n### Sample Space: The Universe of Possibilities\n\nThe **sample space** (denoted $\\Omega$, capital omega) represents the set of all *mutually exclusive* and *collectively exhaustive* outcomes of a random experiment.\n\n**Formal Definition:**\n```math\n\\Omega = \\{\\omega_1, \\omega_2, \\ldots, \\omega_n\\}\n```\n\nwhere each $\\omega_i$ represents an atomic outcome.\n\n**Example:** Rolling a standard six-sided die yields:\n```math\n\\Omega = \\{1, 2, 3, 4, 5, 6\\}\n```\n\nEach outcome is **equiprobable** under the assumption of fairness, embodying the **principle of indifference** (also called the **principle of insufficient reason**, attributed to Laplace).\n\n### Events: Measurable Subsets\n\nAn **event** $A$ is a subset of the sample space \u2014 formally, an element of the **sigma-algebra** $\\mathcal{F}$ defined on $\\Omega$.\n\n**Definition:**\n```math\nA \\subseteq \\Omega, \\quad A \\in \\mathcal{F}\n```\n\n**Example:** Define event $A$ = \"rolling an even number\"\n\nThen:\n```math\nA = \\{2, 4, 6\\} \\subset \\Omega\n```\n\nEvents can be:\n- **Elementary** (singleton sets): $\\{3\\}$\n- **Compound** (multiple outcomes): $\\{2, 4, 6\\}$\n- **Certain** (the entire sample space): $\\Omega$\n- **Impossible** (the empty set): $\\emptyset$\n\n### Kolmogorov's Axioms: The Rules of the Game\n\nIn 1933, Andrey Kolmogorov established the **axiomatic foundation** of modern probability theory. Think of these as the \"rules of reality\" \u2014 like the laws of physics in *Star Trek*, even in alternate universes, these axioms hold.\n\nGiven a sample space $\\Omega$ and a sigma-algebra $\\mathcal{F}$, a probability measure $P: \\mathcal{F} \\to [0,1]$ satisfies:\n\n**Axiom 1 (Non-negativity):**\n```math\nP(A) \\geq 0, \\quad \\forall A \\in \\mathcal{F}\n```\n\nProbabilities are never negative. This ensures **physical realizability**.\n\n**Axiom 2 (Normalization):**\n```math\nP(\\Omega) = 1\n```\n\nSomething must happen. The total probability mass equals unity. Like in *The Hitchhiker's Guide*, the answer may be 42, but certainty is always 1.\n\n**Axiom 3 (Countable Additivity):**\n\nFor any countable collection of **mutually disjoint** events $\\{A_1, A_2, \\ldots\\}$:\n\n```math\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i)\n```\n\nThis is the **additivity principle** \u2014 probabilities of disjoint events sum.\n\n> **Historical Note:** These axioms resolved centuries of philosophical debate about probability. Before Kolmogorov, probability was a mess of intuitions and paradoxes \u2014 like trying to define \"time\" before Einstein gave us special relativity.\n\n## The Classical Probability Model\n\nUnder the assumption of **equally likely outcomes** (the **classical model**), we have:\n\n```math\nP(A) = \\frac{|A|}{|\\Omega|} = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\n```\n\nwhere $|A|$ denotes the **cardinality** of set $A$.\n\n### Worked Example: The Fair Coin\n\nConsider flipping a fair coin. The sample space is:\n\n```math\n\\Omega = \\{H, T\\}\n```\n\nAssuming fairness (symmetry):\n```math\nP(H) = P(T) = \\frac{1}{2}\n```\n\nVerify Axiom 2:\n```math\nP(\\Omega) = P(H) + P(T) = \\frac{1}{2} + \\frac{1}{2} = 1 \\quad \\checkmark\n```\n\nThe axioms are consistent! This simple experiment is the **prototype** for countless probability models, from quantum mechanics (spin measurements) to computer science (random bit generation).\n\n### Worked Example: The Lucky Die\n\n**Problem:** What is $P(A)$ where $A$ = \"rolling less than 4\"?\n\n**Solution:**\n\nDefine the event explicitly:\n```math\nA = \\{1, 2, 3\\}\n```\n\nSince all outcomes are equiprobable under the classical model:\n```math\nP(A) = \\frac{|A|}{|\\Omega|} = \\frac{3}{6} = \\frac{1}{2} = 0.5\n```\n\n**Answer:** There is a 50% probability of rolling less than 4.\n\n> **\ud83d\udca1 Interactive Visualization Coming Soon!**\n> \n> *Explore probability with dynamic Venn diagrams \u2014 drag events, adjust probabilities, and watch the axioms come to life in real-time. Like the holodeck from Star Trek, but for mathematics!*\n\n## Applications Across Disciplines\n\nProbability theory is not merely abstract mathematics \u2014 it's the **lingua franca** of uncertainty quantification.\n\n**Meteorology:** Weather forecasting relies on probabilistic models to predict atmospheric dynamics. The \"30% chance of rain\" is a **conditional probability** statement given current observations.\n\n**Quality Control:** Manufacturing processes use **statistical process control** (SPC) to estimate defect rates via probability distributions, minimizing Type I and Type II errors.\n\n**Finance:** Modern portfolio theory (Markowitz, 1952) uses probability to model expected returns and risk (variance), enabling optimal asset allocation.\n\n**Machine Learning:** Every classification algorithm \u2014 from logistic regression to deep neural networks \u2014 fundamentally computes conditional probabilities $P(y|x)$ where $y$ is the label and $x$ is the input feature vector.\n\n**Quantum Mechanics:** The **Born rule** interprets the wavefunction $|\\psi\\rangle$ as encoding probability amplitudes, with $|\\langle x|\\psi\\rangle|^2$ giving the probability density of measuring position $x$.\n\n## Practice Problems\n\n> **Problem 1:** Roll a fair six-sided die. Compute $P(B)$ where $B$ = \"rolling greater than 4\".\n> \n> **Problem 2:** A bag contains 3 red, 2 blue, and 5 green marbles. Using the classical model, calculate $P(\\text{green})$.\n> \n> **Problem 3 (Challenging):** Can two mutually exclusive events $A$ and $B$ (where $A \\cap B = \\emptyset$) also be statistically independent? Prove or provide a counterexample. *Hint: Recall that independence requires $P(A \\cap B) = P(A) \\cdot P(B)$.*\n\n## The Conceptual Map\n\nYou've now acquired the fundamental **vocabulary** of probability:\n\n1. **Sample spaces** ($\\Omega$) define the universe of possibilities\n2. **Events** ($A \\subseteq \\Omega$) represent measurable outcomes\n3. **Probability measures** ($P$) satisfy Kolmogorov's three axioms\n4. **Classical model** assumes equiprobable outcomes\n\nThese concepts form the **algebraic structure** upon which all of stochastic analysis rests. Like learning the alphabet before reading Shakespeare, you now have the symbols to construct probabilistic narratives.\n\n## The Road Ahead\n\nIn our next lesson, we'll explore **conditional probability** and **Bayes' theorem** \u2014 the mathematical machinery that updates beliefs when new evidence arrives. Think of it as the \"plot twist\" mechanism in probability theory.\n\nAs Sherlock Holmes might say: *\"When you have eliminated the impossible, whatever remains, however improbable, must be the truth.\"* Bayes' theorem gives us the mathematical framework to actually compute those probabilities!\n",
      "status": "published",
      "order": 1,
      "createdAt": "2025-10-25T12:59:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "foundations-2",
      "courseId": "foundations",
      "title": "When Information Changes Everything",
      "description": "Discover how new evidence transforms probabilities through conditional probability and Bayes' theorem.",
      "content": "# When Information Changes Everything\n\nPicture this: You're watching the sky. Dark clouds gather. Suddenly, the probability of rain isn't just a number \u2014 it's *updated* by what you see.\n\nThis is the power of **conditional probability**: understanding how new information reshapes our beliefs.\n\n## The Mystery of the Medical Test\n\nImagine a disease that affects 1% of people. A test detects it 95% of the time when present, but gives false positives 2% of the time for healthy people.\n\n**You test positive.** Should you panic?\n\nLet's find out using the tools you'll learn in this lesson.\n\n## Conditional Probability: Zooming In\n\nThe **conditional probability** P(A|B) asks: \"What's the probability of A, *given* that B has occurred?\"\n\n```math\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{when } P(B) > 0\n```\n\n**Intuition:** If we know B happened, our sample space shrinks to B. We then measure how much of B overlaps with A.\n\n> **\ud83d\udca1 Interactive Visualization Coming Soon!**\n> \n> *Watch Venn diagrams dynamically shrink and highlight as you apply conditions \u2014 see conditional probability in action!*\n\n## Story 1: Drawing Cards\n\nA standard deck has 52 cards. What's P(Ace | Spade)?\n\n**Solution:**\n- A = {card is Ace}, B = {card is Spade}\n- A \u2229 B = {Ace of Spades}\n- P(A \u2229 B) = 1/52, P(B) = 13/52\n\n```math\nP(A|B) = \\frac{1/52}{13/52} = \\frac{1}{13}\n```\n\n**Answer:** Among spades, 1 in 13 is an Ace.\n\n## Bayes' Theorem: The Information Reverser\n\nBayes' theorem is a superpower \u2014 it lets you *reverse* conditional probabilities:\n\n```math\nP(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n```\n\nThis connects:\n- **Prior belief** P(A)\n- **Likelihood** P(B|A) \n- **Posterior belief** P(A|B)\n\n## Back to the Medical Test\n\nLet D = \"has disease\", T = \"tests positive\"\n\nGiven:\n- P(D) = 0.01 (prior)\n- P(T|D) = 0.95 (true positive rate)\n- P(T|\u00acD) = 0.02 (false positive rate)\n\n**Find:** P(D|T) \u2014 probability you have the disease given a positive test.\n\n**Step 1:** Compute P(T) using total probability:\n\n```math\nP(T) = P(T|D)P(D) + P(T|\u00acD)P(\u00acD)\n     = (0.95)(0.01) + (0.02)(0.99)\n     = 0.0293\n```\n\n**Step 2:** Apply Bayes' theorem:\n\n```math\nP(D|T) = \\frac{P(T|D) \\cdot P(D)}{P(T)} = \\frac{0.95 \\times 0.01}{0.0293} \\approx 0.324\n```\n\n**Surprising Answer:** Even with a positive test, there's only a 32% chance you have the disease!\n\nThis is because the disease is rare (low prior), so most positives are false alarms.\n\n> **\ud83d\udca1 Interactive Bayes Calculator Coming Soon!**\n> \n> *Adjust priors, likelihoods, and see posteriors update instantly \u2014 perfect for understanding medical tests, spam filters, and more!*\n\n## Where This Matters\n\n\n\n\n\n## Your Turn\n\n**Practice Questions:**\n1. A biased coin has P(H) = 0.6. If flipped twice, what's P(first = H | total heads = 1)?\n2. A machine makes 5% defects. A test catches 90% of defects and flags 3% of good items. Find P(defect | flagged).\n3. Explain in your own words how Bayes' theorem \"reverses\" conditional probabilities.\n\n## The Journey Continues\n\nYou've now mastered:\n- **Conditional probability** \u2014 updating beliefs with evidence\n- **Bayes' theorem** \u2014 the mathematical engine of inference\n- **Real-world impact** \u2014 from medicine to AI\n\n**Next Adventure:** Random variables and expectations \u2014 turning probability into numbers we can compute and predict!\n",
      "status": "published",
      "order": 2,
      "createdAt": "2025-10-25T13:06:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "foundations-3",
      "courseId": "foundations",
      "title": "Random Variables: Probability Meets Numbers",
      "description": "Transform random outcomes into numbers, compute averages, and discover the law of large numbers through interactive exploration.",
      "content": "# Random Variables: Probability Meets Numbers\n\nSo far, we've dealt with abstract outcomes \u2014 heads/tails, sunny/rainy, Ace/King. But what if we want to *quantify* randomness? Enter **random variables** \u2014 the bridge between probability and numerical analysis.\n\n## What Is a Random Variable?\n\nA **random variable (RV)** assigns a number to each outcome of a random experiment.\n\n```math\nX: \\Omega \\to \\mathbb{R}\n```\n\n**Example:** Roll a die. Let X = the number shown. Then X(outcome) \u2208 {1,2,3,4,5,6}.\n\n**Why care?** Random variables let us compute averages, spreads, and make predictions.\n\n## Types of Random Variables\n\n### Discrete Random Variables\nTake on countable values (like dice rolls, coin flips counted).\n\n**Probability Mass Function (PMF):**\n\n```math\np(x) = P(X = x), \\quad \\sum p(x) = 1\n```\n\n### Continuous Random Variables  \nTake values from intervals (like heights, times).\n\n**Probability Density Function (PDF):**\n\n```math\nP(a \\le X \\le b) = \\int_a^b f(x)\\,dx, \\quad \\int_{-\\infty}^{\\infty} f(x)\\,dx = 1\n```\n\n## Story 1: Rolling the Die\n\nLet X = result of rolling a fair six-sided die.\n\n| x | 1 | 2 | 3 | 4 | 5 | 6 |\n|---|---|---|---|---|---|---|\n| P(X=x) | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 | 1/6 |\n\nThis is a **uniform discrete distribution**.\n\n## Expected Value: The Long-Run Average\n\nThe **expected value** E[X] is the weighted average of all possible values:\n\n```math\nE[X] = \\sum x \\cdot P(X=x) \\quad \\text{(discrete)}\n```\n\nFor our die:\n\n```math\nE[X] = 1(\\frac{1}{6}) + 2(\\frac{1}{6}) + \\cdots + 6(\\frac{1}{6}) = \\frac{21}{6} = 3.5\n```\n\n**Interpretation:** If you roll the die thousands of times, the average approaches 3.5.\n\n**Fun fact:** 3.5 is not even a possible outcome! Expectations don't have to be achievable values.\n\n## Story 2: Coin Flips and Convergence\n\nFlip a fair coin repeatedly. Let p = 0.5 be the true probability of heads.\n\nDefine $\\hat{p}_n$ = (number of heads) / n.\n\n**Question:** As n increases, what happens to $\\hat{p}_n$?\n\n**Answer:** By the **Law of Large Numbers**, $\\hat{p}_n$ converges to p = 0.5!\n\n### Experience It Yourself\n\n```component\n{\"name\":\"FlipConvergence\",\"props\":{\"p\":0.5,\"trials\":500,\"updateIntervalMs\":30,\"batch\":50,\"height\":400}}\n```\n\n**Instructions:** Click \"Start\" and watch the estimated probability converge to the true value. Try changing the speed and see convergence in real-time!\n\n## Variance: Measuring Spread\n\nThe **variance** quantifies how spread out a distribution is:\n\n```math\n\\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2\n```\n\n**Standard deviation** = \u221aVar(X)\n\n### Example: Die Roll Variance\n\n```math\nE[X^2] = (1^2 + 2^2 + \\cdots + 6^2)/6 = 91/6\n```\n\n```math\n\\text{Var}(X) = 91/6 - (3.5)^2 = 35/12 \\approx 2.92\n```\n\n**Standard deviation:** \u221a2.92 \u2248 1.71\n\n> **\ud83d\udca1 Interactive PMF/PDF Explorer Coming Soon!**\n> \n> *Adjust distribution parameters and watch expected value and variance shift dynamically on interactive charts.*\n\n## Where Random Variables Live\n\n\n\n\n\n## Your Turn\n\n**Practice Questions:**\n1. A coin is flipped 3 times. Let X = number of heads. Find E[X] and Var(X).\n2. X takes values {0,1,2} with P(0)=0.2, P(1)=0.5, P(2)=0.3. Compute E[X] and Var(X).\n3. Why can E[X] = 3.5 for a die even though you can't roll 3.5?\n\n## The Story So Far\n\nYou've now mastered the foundations:\n- **Probability** quantifies uncertainty\n- **Conditional probability** updates beliefs\n- **Random variables** turn outcomes into numbers\n- **Expectations** predict long-run averages\n\n**Next Chapter:** Markov chains \u2014 where probabilities *evolve* through time and state transitions!\n",
      "status": "published",
      "order": 3,
      "createdAt": "2025-10-25T13:12:00.000Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    },
    {
      "id": "chains-1",
      "courseId": "chains",
      "title": "Enter the Markov Chain: Memory-Free Transitions",
      "description": "Discover the memoryless property and see your first Markov chain in action.",
      "content": "# Enter the Markov Chain: Memory-Free Transitions\n\nImagine a system that evolves through time, jumping from state to state. **But here's the twist:** the future depends *only* on where you are now, not on how you got there.\n\nThis is the **Markov property** \u2014 and it unlocks an entire universe of stochastic models.\n\n## The Big Idea\n\nA **Markov chain** is a sequence of random states where:\n\n> The probability of the next state depends only on the current state, not on past history.\n\nMathematically:\n\n```math\nP(X_{n+1} = j \\mid X_n = i, X_{n-1}, X_{n-2}, \\ldots) = P(X_{n+1} = j \\mid X_n = i)\n```\n\n**Translation:** \"Where you go next depends only on where you are now \u2014 your past is irrelevant.\"\n\n## Story 1: The Weather Model\n\nConsider a simple weather system with two states:\n- **S** = Sunny\n- **R** = Rainy\n\nObservations show:\n- After a sunny day, 70% of tomorrows are sunny, 30% rainy\n- After a rainy day, 40% of tomorrows are sunny, 60% rainy\n\n**Transition Matrix:**\n\n```matrix\n        S     R\n  S [ 0.7   0.3 ]\n  R [ 0.4   0.6 ]\n```\n\nEach row shows where you can go from that state. Rows sum to 1 (you must go somewhere).\n\n> **\ud83d\udca1 Interactive State Diagram Coming Soon!**\n> \n> *Visualize states as nodes and transitions as arrows \u2014 click to follow the chain through time!*\n\n## The Anatomy of a Markov Chain\n\n### 1. State Space\nThe set of all possible states: S = {S, R} in our weather example.\n\n### 2. Transition Probabilities\nP(i\u2192j) = probability of moving from state i to state j.\n\n### 3. Initial Distribution\nWhere does the chain start? \u03c0\u2080 = [P(start in S), P(start in R)].\n\n## Simulating the Weather\n\nStart on a sunny day. Use the transition matrix to generate next days:\n\n- Day 0: S (given)\n- Day 1: With prob 0.7 \u2192 S, with prob 0.3 \u2192 R. Say we get S.\n- Day 2: From S, again 0.7 \u2192 S, 0.3 \u2192 R. Say we get R.\n- Day 3: From R, 0.4 \u2192 S, 0.6 \u2192 R. Say we get R.\n- ...\n\nThe sequence {S, S, R, R, ...} is one **realization** of the Markov chain.\n\n## Why \"Memoryless\" Matters\n\nThe memoryless property makes Markov chains:\n- **Tractable** \u2014 easy to analyze mathematically\n- **Efficient** \u2014 need only track current state\n- **Widely applicable** \u2014 many real systems have this property (or approximate it)\n\n## Where You'll Find Markov Chains\n\n\n\n\n\n## Explore Convergence\n\nHere's a related question: if you flip a coin many times, does the proportion of heads converge to the true probability?\n\n**Spoiler:** Yes! This is the **Law of Large Numbers** in action.\n\n```component\n{\"name\":\"FlipConvergence\",\"props\":{\"p\":0.7,\"trials\":600,\"updateIntervalMs\":25,\"batch\":40,\"height\":400}}\n```\n\n**Try it:** Adjust the true probability (p) and watch convergence. This same idea applies to Markov chains \u2014 long-run frequencies converge to steady-state probabilities!\n\n## Your Turn\n\n**Practice Questions:**\n1. Draw a state diagram for a 3-state chain: {A, B, C} with transitions A\u2192B (0.5), A\u2192C (0.5), B\u2192A (1.0), C\u2192A (1.0).\n2. Explain why the Markov property is \"memoryless.\"\n3. Can you think of a real-world process that is NOT Markovian? (Hint: stock prices with trends)\n\n## The Adventure Begins\n\nYou've just entered the world of Markov chains:\n- **States** represent positions in the system\n- **Transitions** govern movement between states\n- **Memoryless** \u2014 only the present matters\n\n**Next:** We'll dig deeper into transition matrices and learn how to compute multi-step probabilities!\n",
      "status": "published",
      "order": 1,
      "createdAt": "2025-10-25T11:37:21.531Z",
      "updatedAt": "2025-11-06T12:00:00.000Z"
    }
  ]
}